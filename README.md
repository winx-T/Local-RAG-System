# ğŸ§  Local RAG System â€“ Smart, Simple, and Powerful

A **zero-setup**, **fully local Retrieval-Augmented Generation (RAG) system** that lets you instantly ask questions about your own **PDFs, Word, Excel, PowerPoint, Text, CSV, or HTML files** â€” **with no cloud, no API keys, and complete privacy**.

Built for **everyone**:
- ğŸ§© Beginners who just want a simple, working personal AI.
- ğŸ§  Power users who want reranking, hybrid search, and multilingual embeddings.

##  Whatâ€™s New in this version
| Feature                        | Description                                                               |
| ------------------------------ | ------------------------------------------------------------------------- |
| ğŸ’¡ **General Knowledge Mode**  | Ask questions without documents (â€œfrom your knowledgeâ€).                  |
| ğŸ’¬ **Smarter Chat System**     | Handles casual talk, document Q&A, or general queries automatically.      |
| ğŸ§  **Intent Detection**        | Detects whether to use documents or general knowledge via regex patterns. |
| ğŸ§° **Improved Cache Handling** | Displays â€œfrom memoryâ€ responses for cached answers.                      |
| ğŸ›¡ï¸ **Error Resilience**       | Handles runtime issues gracefully without crashes.                        |
| âœ¨ **Enhanced UX**              | Clearer chat messages, emojis, and helpful prompts.                       |


---

## ğŸ” What is RAG?

**Retrieval-Augmented Generation (RAG)** is an AI technique that combines *information retrieval* with *text generation*.  
Instead of relying only on what a model â€œknowsâ€ from training, RAG allows the system to **search your documents** in real time and use that knowledge to produce accurate, grounded answers.

<p align="center">
  <img 
    src="https://cdn.prod.website-files.com/651c34ac817aad4a2e62ec1b/655664de69b30a6d00f0960c_gaJkRvUmWHsWtnAGlNtjQJYhSzHvUwZHvV7nDU3kQJ6EyEI1C4v6HRysXIw28UlXK3QT4yU0rgTD7v1cUgbl5nB71emE5vqz9Y0VlvLjg10BgaLcOvI4Zauu9AKU6EKWN5rIwIKPs8CSYd0CiX2Gg5g.png" 
    alt="ğŸ§  Local RAG System Banner"
    style="max-width: 90%; height: auto; border-radius: 12px; box-shadow: 0 4px 15px rgba(0,0,0,0.15);"
  >
</p>

### ğŸ§  How RAG Works

1. **You ask a question.**  
2. The system **retrieves** the most relevant chunks of text from your local knowledge base (PDFs, Word docs, etc.).  
3. These chunks are **combined** with your question to form a detailed prompt.  
4. The **language model** (LLM) then generates an answer â€” using the retrieved data as factual grounding.  
5. The answer is shown with **source references** so you know exactly where it came from.

### âœ… Why It Matters

- Prevents AI â€œhallucinationsâ€ by grounding answers in real documents.  
- Works with **your own data**, not just whatâ€™s in the modelâ€™s memory.  
- No retraining needed â€” just add documents and start asking!  
- In your local version, everything happens **offline** and **privately**.

---

## ğŸš€ Highlights

| Feature | Description |
|----------|--------------|
| âš™ï¸ **Zero Configuration** | Works out of the box â€“ just run the script |
| ğŸ§­ **Setup Wizard** | Friendly first-run setup: language, speed, and quality |
| ğŸ’¬ **Plain English Interface** | No technical jargon â€“ â€œdocuments,â€ not â€œembeddingsâ€ |
| ğŸ§  **Smart Chunking** | Sentence-aware text splitting with overlap |
| ğŸ¯ **Cross-Encoder Re-ranking** | High-accuracy context selection using `ms-marco-MiniLM-L-6-v2` |
| ğŸ” **Semantic Search** | Embeddings via `sentence-transformers` |
| ğŸ•°ï¸ **Conversation Memory** | Keeps track of your recent Q&A exchanges |
| ğŸ’¾ **Persistent Knowledge Base** | Stores your documents locally using **ChromaDB** |
| ğŸ›¡ï¸ **100% Local Privacy** | All processing stays on your machine â€“ no cloud calls |
| ğŸŒ **Multilingual Support** | English, French, Arabic, Spanish, and more |

---

## ğŸ§© Core Components

### ğŸ§­ 1ï¸âƒ£ First-Time Setup Wizard
On first run, youâ€™ll be guided through:
1. Checking if Ollama is running  
2. Choosing your language (English, French, Arabic, etc.)  
3. Selecting **speed** or **best quality** mode  

Your preferences are saved automatically for future sessions.

---

### ğŸ“„ 2ï¸âƒ£ Smart Document Reader
Automatically extracts text from:
- PDF (.pdf)
- Word (.docx, .doc)
- Excel (.xlsx, .xls)
- PowerPoint (.pptx, .ppt)
- Text & Markdown (.txt, .md)
- CSV (.csv)
- HTML (.html, .htm)

ğŸ§  It also:
- Auto-detects formats  
- Skips unreadable files gracefully  
- Uses multiple encodings for compatibility  

---

### âœ‚ï¸ 3ï¸âƒ£ Intelligent Chunking
Splits text into **~600-character segments** with a **20-word overlap**  
â†’ Ensures smooth transitions between chunks and preserves sentence meaning.

---

### ğŸ“š 4ï¸âƒ£ Local Knowledge Base
Documents are:
- Embedded using **SentenceTransformers**
- Stored persistently with **ChromaDB**
- Tagged with metadata (source, size, timestamp)

---

### ğŸ” 5ï¸âƒ£ Semantic + Reranked Search
1. Embeds your question into vector space  
2. Retrieves top 20 relevant sections  
3. (Optional) Reranks them using **CrossEncoder**  
4. Assembles the top chunks as context for the LLM

ğŸ’¡ Results are cached for 24 hours to speed up repeated queries.

---

### ğŸ’¬ 6ï¸âƒ£ Chat Mode
Interactive chat with your documents:

````bash
You: What is cloud computing?
ğŸ” Searching your documents...
ğŸ’­ Thinking...

ğŸ“ ANSWER:
Cloud computing is a model for delivering computing services over the internet...

ğŸ’¡ Sources: cloud_intro.pdf
`````

ğŸ§° Commands:

* `docs` â†’ show your document list
* `clear` â†’ reset chat memory
* `exit` â†’ quit chat mode

---

## âš™ï¸ Installation

### ğŸ§  Requirements

* **Python 3.8+**
* **Ollama** installed and running
  ğŸ‘‰ [Download here](https://ollama.ai/download)

---

### ğŸ“¦ Install Dependencies

```bash
pip install chromadb sentence-transformers requests numpy tqdm PyPDF2
# Optional (for extra formats)
pip install python-docx python-pptx openpyxl beautifulsoup4
```

### ğŸš€ Installation

1. Clone or download the repository

   ```bash
   git clone https://github.com/your-username/simple-local-rag.git
   cd simple-local-rag
   ```
2. Install dependencies

   ```bash
   pip install -r requirements.txt
   ```

---

### â–¶ï¸ Run It

```bash
python rag_ollama.py
```

**First run** â†’ setup wizard (language + model preferences)
**Next runs** â†’ jump straight into chat or add new docs

---

## ğŸ  Main Menu

```
ğŸ  MAIN MENU
1. ğŸ’¬ Chat with your documents
2. â• Add documents
3. ğŸ“ Add entire folder
4. ğŸ“š View my documents
5. ğŸ—‘ï¸ Remove a document
6. âš™ï¸ Settings
7. â“ Help
8. ğŸšª Exit
```

---

## âš™ï¸ Settings Menu

| Option         | Description                                |
| -------------- | ------------------------------------------ |
| Show sources   | Toggle document sources in answers         |
| Stream answers | Stream text as itâ€™s generated              |
| Language       | Change preferred language                  |
| Quality mode   | Switch between faster or best-quality mode |
| Ollama model   | Set LLM (e.g., `llama3.2:3b`)              |

---

## ğŸ§  Example Workflow

```bash
python rag_ollama.py
```

```
ğŸ‘‰ Choose (1-8): 2
ğŸ“‚ Add your documents

ğŸ‘‰ Choose (1-8): 1
ğŸ’¬ Ask: What is machine learning?

ğŸ§  ANSWER:
Machine learning is a subset of AI that enables systems to learn from data...
ğŸ’¡ Sources: ai_intro.pdf
```

---

## ğŸ“Š Performance Comparison

| Mode    | Description    | Retrieval Accuracy | Speed                             |
| ------- | -------------- | ------------------ | --------------------------------- |
| âš¡ Fast  | No reranking   | 70%                | Very fast                         |
| ğŸ¯ Best | With reranking | 87%                | Slightly slower but more accurate |

---

## ğŸ” Privacy & Local Processing

âœ… 100% Local â€“ No cloud uploads
âœ… No API keys required
âœ… All data stored under `./my_knowledge_base`
âœ… Safe for confidential or private use

---

## ğŸ§° Troubleshooting

| Problem              | Solution                                    |
| -------------------- | ------------------------------------------- |
| âŒ Ollama not found   | Run `ollama serve`                          |
| âš ï¸ Slow response     | Disable reranking (Settings â†’ Quality Mode) |
| ğŸ’¾ High memory usage | Reduce chunk size or disable reranking      |
| ğŸ“ No answers        | Add more relevant documents                 |
| ğŸ”Œ Connection error  | Ensure Ollama is running locally            |

---

## ğŸš€ Future Roadmap

* [ ] Web-based UI
* [ ] Multi-modal retrieval (images, tables)
* [ ] Document comparison & citation linking
* [ ] Graph-based search
* [ ] Fine-tuning assistant behavior

---

## ğŸªª License

**MIT License** â€“ free for personal and commercial use.

---

## â¤ï¸ Credits

Built with:

* [Ollama](https://ollama.ai/) â€“ local LLM inference
* [ChromaDB](https://www.trychroma.com/) â€“ vector storage
* [SentenceTransformers](https://www.sbert.net/) â€“ semantic embeddings
* [CrossEncoders](https://www.sbert.net/examples/applications/cross-encoder/) â€“ reranking

---

â­ **If you find this helpful, consider starring the project!**
